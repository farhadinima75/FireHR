{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "> Deep Learning models used to map burned areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os, sys\n",
    "from fastai.vision.all import *\n",
    "import FireHR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def expand_filter(x, ks=3):\n",
    "    with torch.no_grad():\n",
    "        k5 = nn.Conv2d(1, 1, kernel_size=ks, padding=ks//2, padding_mode='reflect', bias=False)\n",
    "        k5.weight.data = torch.ones(1, 1, ks, ks)/(ks*ks)\n",
    "        xbuffer = k5(x[:,-1].unsqueeze(1))\n",
    "        x = torch.cat([x[:,:-1], xbuffer], dim=1)\n",
    "        return x\n",
    "    \n",
    "class ChLin(Module):\n",
    "    def __init__(self, ni, nf):\n",
    "        self.chlin = nn.Sequential(\n",
    "            nn.Linear(ni, nf, bias=False), nn.BatchNorm1d(nf), nn.ReLU(inplace=True))\n",
    "    def forward(self, x): \n",
    "        sh = x.shape\n",
    "        x = x.permute(0,2,3,1).contiguous().view(sh[0]*sh[2]*sh[3], sh[1])\n",
    "        x = self.chlin(x).view(sh[0],sh[2],sh[3], -1).permute(0,3,1,2).contiguous()\n",
    "        return x\n",
    "    \n",
    "class FireHR(Module):\n",
    "    def __init__(self, ni, nc):\n",
    "        self.conv = ConvLayer(1, 8)\n",
    "        self.chlin = nn.Sequential(ChLin(ni+8, 128), ChLin(128, 64))\n",
    "        self.middleconv = nn.Sequential(ConvLayer(64, 128), ConvLayer(128, 64))\n",
    "        self.finalconv = nn.Conv2d(64, nc, kernel_size=1, bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.cat([x[:,:-1], self.conv(x[:,-1].unsqueeze(1))], dim=1)\n",
    "        x = self.chlin(x)\n",
    "        x = self.middleconv(x)\n",
    "        return self.finalconv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FireHR(\n",
       "  (conv): ConvLayer(\n",
       "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (chlin): Sequential(\n",
       "    (0): ChLin(\n",
       "      (chlin): Sequential(\n",
       "        (0): Linear(in_features=14, out_features=128, bias=False)\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ChLin(\n",
       "      (chlin): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=64, bias=False)\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (middleconv): Sequential(\n",
       "    (0): ConvLayer(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (1): ConvLayer(\n",
       "      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (finalconv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FireHR(6,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_WEIGHTS = sys.modules[FireHR.__name__].__path__[0] + '/data/model512.pth'\n",
    "def load_pretrained_model(weights=_WEIGHTS, ni=6, nc=1, half_precision=True, gpu=True):\n",
    "    model = FireHR(ni,nc)\n",
    "    st = torch.load(weights, map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(st['model'])\n",
    "    if gpu: \n",
    "        if half_precision: model = model.half()\n",
    "        if torch.cuda.is_available():\n",
    "            model = model.cuda()\n",
    "        else: \n",
    "            warnings.warn('GPU is not available. torch.cuda.is_available() returned False.')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cuda', index=0), 'torch.cuda.HalfTensor')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#local\n",
    "model = load_pretrained_model()\n",
    "model.conv[0].weight.device, model.conv[0].weight.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_data.ipynb.\n",
      "Converted 02_models.ipynb.\n",
      "Converted 03_predict.ipynb.\n",
      "Converted 04_cli.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (banet_dev)",
   "language": "python",
   "name": "banet_dev"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
